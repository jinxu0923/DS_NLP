{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265134f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93698380",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edcf0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    def read_text(self,is_train_data):\n",
    "        #read that data\n",
    "        #is_train_data==True   reading the training data \n",
    "        #is_train_data==False  reading the testing data \n",
    "        datas = []\n",
    "        labels = []\n",
    "        if(is_train_data):\n",
    "            #training data folder\n",
    "            INFOCOM_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/train//INFOCOM/\"\n",
    "            ISCAS_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/train//ISCAS/\"\n",
    "            SIGGRAPH_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/train//SIGGRAPH/\"\n",
    "            VLDB_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/train//VLDB/\"\n",
    "            WWW_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/train//WWW/\" \n",
    "        else:\n",
    "            #testing data folder\n",
    "            INFOCOM_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/valid/INFOCOM/\"\n",
    "            ISCAS_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/valid/ISCAS/\"\n",
    "            SIGGRAPH_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/valid/SIGGRAPH/\"\n",
    "            VLDB_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/valid/VLDB/\"\n",
    "            WWW_path = \"C://Users//Jin Xu//Desktop//NLP_project//new_data/\"+str(fold)+\"/valid/WWW/\"\n",
    "        INFOCOM_files= os.listdir(INFOCOM_path) \n",
    "        ISCAS_files = os.listdir(ISCAS_path)\n",
    "        SIGGRAPH_files = os.listdir(SIGGRAPH_path)\n",
    "        VLDB_files = os.listdir(VLDB_path)\n",
    "        WWW_files = os.listdir(WWW_path)\n",
    "        \n",
    "        \n",
    "        for file_name in INFOCOM_files: \n",
    "            file_position = INFOCOM_path + file_name\n",
    "            with open(file_position, \"r\",encoding='utf-8') as f:\n",
    "                data = f.read() \n",
    "                datas.append(data)\n",
    "                labels.append([1,0,0,0,0])  #transform the label into vector\n",
    "        \n",
    "        for file_name in ISCAS_files:\n",
    "            file_position = ISCAS_path + file_name \n",
    "            with open(file_position, \"r\",encoding='utf-8') as f:\n",
    "                data = f.read()\n",
    "                datas.append(data)\n",
    "                labels.append([0,1,0,0,0])  #transform the label into vector\n",
    "\n",
    "        for file_name in SIGGRAPH_files:\n",
    "            file_position = SIGGRAPH_path + file_name \n",
    "            with open(file_position, \"r\",encoding='utf-8') as f:\n",
    "                data = f.read()\n",
    "                datas.append(data)\n",
    "                labels.append([0,0,1,0,0])  #transform the label into vector\n",
    "\n",
    "        for file_name in VLDB_files:\n",
    "            file_position = VLDB_path + file_name \n",
    "            with open(file_position, \"r\",encoding='utf-8') as f:\n",
    "                data = f.read()\n",
    "                datas.append(data)\n",
    "                labels.append([0,0,0,1,0])  #transform the label into vector\n",
    "\n",
    "        for file_name in WWW_files:\n",
    "            file_position = WWW_path + file_name \n",
    "            with open(file_position, \"r\",encoding='utf-8') as f:\n",
    "                data = f.read()\n",
    "                datas.append(data)\n",
    "                labels.append([0,0,0,0,1])  #transform the label into vector\n",
    "        return datas, labels\n",
    "    \n",
    "    def word_count(self, datas):\n",
    "        \n",
    "        dic = {}\n",
    "        for data in datas:\n",
    "            data_list = data.split()\n",
    "            for word in data_list:\n",
    "                word = word.lower()\n",
    "                if(word in dic):\n",
    "                    dic[word] += 1\n",
    "                else:\n",
    "                    dic[word] = 1\n",
    "        word_count_sorted = sorted(dic.items(), key=lambda item:item[1], reverse=True)\n",
    "        return  word_count_sorted\n",
    "    \n",
    "    def word_index(self, datas, vocab_size):\n",
    "       \n",
    "        word_count_sorted = self.word_count(datas)\n",
    "        word2index = {}\n",
    "        \n",
    "        word2index[\"<unk>\"] = 0\n",
    "        \n",
    "        word2index[\"<pad>\"] = 1\n",
    "        \n",
    "        \n",
    "        vocab_size = min(len(word_count_sorted), vocab_size)\n",
    "        for i in range(vocab_size):\n",
    "            word = word_count_sorted[i][0]\n",
    "            word2index[word] = i + 2\n",
    "          \n",
    "        return word2index, vocab_size\n",
    "    \n",
    "    def get_datasets(self, vocab_size, embedding_size, max_len):\n",
    "        \n",
    "        train_datas, train_labels = self.read_text(is_train_data=True)\n",
    "        word2index, vocab_size = self.word_index(train_datas, vocab_size)\n",
    "        \n",
    "        test_datas, test_labels = self.read_text(is_train_data = False)\n",
    "        \n",
    "        train_features = []\n",
    "        for data in train_datas:\n",
    "            feature = []\n",
    "            data_list = data.split()\n",
    "            for word in data_list:\n",
    "                word = word.lower()\n",
    "                if word in word2index:\n",
    "                    feature.append(word2index[word])\n",
    "                else:\n",
    "                    feature.append(word2index[\"<unk>\"])\n",
    "                if(len(feature)==max_len):\n",
    "                    break\n",
    "            \n",
    "            feature = feature + [word2index[\"<pad>\"]] * (max_len - len(feature))\n",
    "            train_features.append(feature)\n",
    "            \n",
    "        test_features = []\n",
    "        for data in test_datas:\n",
    "            feature = []\n",
    "            data_list = data.split()\n",
    "            for word in data_list:\n",
    "                word = word.lower() \n",
    "                if word in word2index:\n",
    "                    feature.append(word2index[word])\n",
    "                else:\n",
    "                    feature.append(word2index[\"<unk>\"]) \n",
    "                if(len(feature)==max_len):\n",
    "                    break\n",
    "           \n",
    "            feature = feature + [word2index[\"<pad>\"]] * (max_len - len(feature))\n",
    "            test_features.append(feature)\n",
    "            \n",
    "        train_features = torch.LongTensor(train_features)\n",
    "        train_labels = torch.FloatTensor(train_labels)\n",
    "        \n",
    "        test_features = torch.LongTensor(test_features)\n",
    "        test_labels = torch.FloatTensor(test_labels)\n",
    "        \n",
    "        embed = nn.Embedding(vocab_size + 2, embedding_size)\n",
    "        train_features = embed(train_features)\n",
    "        test_features = embed(test_features)\n",
    "        \n",
    "        train_features = Variable(train_features, requires_grad=False)\n",
    "        train_datasets = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "        \n",
    "        test_features = Variable(test_features, requires_grad=False)\n",
    "        test_datasets = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "        return train_datasets, test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8437d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123) \n",
    "\n",
    "vocab_size = 31000   #size of vocabulary\n",
    "embedding_size = 100  #size of word embedding\n",
    "num_classes = 5    #5 classification\n",
    "sentence_max_len = 20  #the maximum of sentence length\n",
    "hidden_size = 16\n",
    "\n",
    "num_layers = 1 #one layer of lstm\n",
    "num_directions = 2  #bidirectional lstm\n",
    "lr = 1e-5\n",
    "batch_size = 64   \n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66df9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "190331bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-LSTM model\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_size,hidden_size, num_layers, num_directions, num_classes):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        \n",
    "        self.input_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = num_directions\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers = num_layers, bidirectional = (num_directions == 2))\n",
    "        self.attention_weights_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.liner = nn.Linear(hidden_size, num_classes)\n",
    "        self.act_func = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #lstm's shape [seq_len, batch, input_size]\n",
    "        #x [batch_size, sentence_length, embedding_size]\n",
    "        x = x.permute(1, 0, 2)         #[sentence_length, batch_size, embedding_size]\n",
    "        \n",
    "        batch_size = x.size(1)\n",
    "        \n",
    "        h_0 = torch.randn(self.num_layers * self.num_directions, batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.randn(self.num_layers * self.num_directions, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        #out[seq_len, batch, num_directions * hidden_size]\n",
    "        #h_n, c_n [num_layers * num_directions, batch, hidden_size]\n",
    "        out, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
    "        #print(out.shape) #20, 16, 32\n",
    "        \n",
    "        #split the output of lstm into forward and backward\n",
    "        (forward_out, backward_out) = torch.chunk(out, 2, dim = 2)\n",
    "        out = forward_out + backward_out  #[seq_len, batch, hidden_size]\n",
    "        out = out.permute(1, 0, 2)  #[batch, seq_len, hidden_size] #16,20,16\n",
    "        \n",
    "        h_n = h_n.permute(1, 0, 2)  #[batch, num_layers * num_directions,  hidden_size]\n",
    "        h_n = torch.sum(h_n, dim=1) #[batch, 1,  hidden_size]\n",
    "        h_n = h_n.squeeze(dim=1)  #[batch, hidden_size]\n",
    "        \n",
    "        attention_w = self.attention_weights_layer(h_n)  #[batch, hidden_size]\n",
    "        attention_w = attention_w.unsqueeze(dim=1) #[batch, 1, hidden_size]\n",
    "        \n",
    "        #print(out.transpose(1,2).shape) #16, 16, 20\n",
    "        attention_context = torch.bmm(attention_w, out.transpose(1, 2))  #[batch, 1, seq_len]\n",
    "        softmax_w = F.softmax(attention_context, dim=-1)  #[batch, 1, seq_len]\n",
    "        \n",
    "        x = torch.bmm(softmax_w, out)  #[batch, 1, hidden_size]\n",
    "        x = x.squeeze(dim=1)  #[batch, hidden_size]\n",
    "        x = self.liner(x)\n",
    "        x = self.act_func(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "947c6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_func):\n",
    "    model.eval()\n",
    "    loss_val = 0.0\n",
    "    corrects = 0.0\n",
    "    preds_total = []\n",
    "    labels_total = []\n",
    "    for datas, labels in test_loader:\n",
    "        datas = datas.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        preds = model(datas)\n",
    "        loss = loss_func(preds, labels)\n",
    "        \n",
    "        loss_val += loss.item() * datas.size(0)\n",
    "        \n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        preds_total.extend(preds.cpu().numpy().tolist())\n",
    "        labels_total.extend(labels.cpu().numpy().tolist())\n",
    "        corrects += torch.sum(preds == labels).item()\n",
    "    test_loss = loss_val / len(test_loader.dataset)\n",
    "    test_acc = corrects / len(test_loader.dataset)\n",
    "    print(\"Test Loss: {}, Test Acc: {}\".format(test_loss, test_acc))\n",
    "    print(\"precision \", precision_score(labels_total, preds_total, average='macro'))\n",
    "    print(\"recall \", recall_score(labels_total, preds_total, average='macro'))\n",
    "    print(\"f1 \", f1_score(labels_total, preds_total, average='macro'))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8f8e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader,test_loader, optimizer, loss_func, epochs):\n",
    "    best_val_acc = 0.0\n",
    "    best_model_params = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch: \", epoch)\n",
    "        model.train()\n",
    "        loss_val = 0.0\n",
    "        corrects = 0.0\n",
    "        for datas, labels in train_loader:\n",
    "            datas = datas.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            preds = model(datas)\n",
    "            loss = loss_func(preds, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_val += loss.item() * datas.size(0)\n",
    "            \n",
    "            preds = torch.argmax(preds, dim=1)\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            corrects += torch.sum(preds == labels).item()\n",
    "        train_loss = loss_val / len(train_loader.dataset)\n",
    "        train_acc = corrects / len(train_loader.dataset)\n",
    "        if(epoch % 1 == 0):\n",
    "            print(\"Train Loss: {}, Train Acc: {}\".format(train_loss, train_acc))\n",
    "            test_acc = test(model, test_loader, loss_func)\n",
    "            if(best_val_acc < test_acc):\n",
    "                best_val_acc = test_acc\n",
    "                best_model_params = copy.deepcopy(model.state_dict())\n",
    "    model.load_state_dict(best_model_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aed94221",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataProcessor()\n",
    "train_datasets, test_datasets = processor.get_datasets(vocab_size=vocab_size, embedding_size=embedding_size, max_len=sentence_max_len)\n",
    "train_loader = torch.utils.data.DataLoader(train_datasets, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_datasets, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "444ceae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTMModel(embedding_size, hidden_size, num_layers, num_directions, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a23bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f375a623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMModel(\n",
       "  (lstm): LSTM(100, 16, bidirectional=True)\n",
       "  (attention_weights_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (liner): Linear(in_features=16, out_features=5, bias=True)\n",
       "  (act_func): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eff44580",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8d14fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51013f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Train Loss: 0.501254797301915, Train Acc: 0.2097938441993417\n",
      "Test Loss: 0.5002152960552863, Test Acc: 0.23555247341655108\n",
      "precision  0.14716214471684236\n",
      "recall  0.18194634619066746\n",
      "f1  0.14118403149118458\n",
      "epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.49808975133119643, Train Acc: 0.2835364093087717\n",
      "Test Loss: 0.4969376289783889, Test Acc: 0.2979657882570504\n",
      "precision  0.14719943632776894\n",
      "recall  0.18857190827677311\n",
      "f1  0.13466764766023204\n",
      "epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4949253008286741, Train Acc: 0.3263844776808916\n",
      "Test Loss: 0.4940398166811251, Test Acc: 0.3261673601479427\n",
      "precision  0.12483707785784937\n",
      "recall  0.19265748305774766\n",
      "f1  0.116143329749622\n",
      "epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4920111164014375, Train Acc: 0.33839579603857484\n",
      "Test Loss: 0.4911234830189677, Test Acc: 0.33587609801202034\n",
      "precision  0.117281194754479\n",
      "recall  0.19494736157308726\n",
      "f1  0.10669934111145774\n",
      "epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4895117497853059, Train Acc: 0.3435930010971877\n",
      "Test Loss: 0.48876724692885654, Test Acc: 0.3407304669440592\n",
      "precision  0.0995823917563048\n",
      "recall  0.19717222275061824\n",
      "f1  0.10588197655408238\n",
      "epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4876020634849662, Train Acc: 0.3444014552174164\n",
      "Test Loss: 0.4871238868544072, Test Acc: 0.34257975034674065\n",
      "precision  0.09749350043330444\n",
      "recall  0.1977871766216473\n",
      "f1  0.10422148272250378\n",
      "epoch:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48617681998430584, Train Acc: 0.3449211757232777\n",
      "Test Loss: 0.4859747832371469, Test Acc: 0.34350439204808136\n",
      "precision  0.10027819855511537\n",
      "recall  0.19831979979075517\n",
      "f1  0.10441652231885094\n",
      "epoch:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4852102849581517, Train Acc: 0.34561413639775945\n",
      "Test Loss: 0.48504043500345173, Test Acc: 0.343042071197411\n",
      "precision  0.09045676998368679\n",
      "recall  0.19787337121932663\n",
      "f1  0.10356005120375913\n",
      "epoch:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4844215987990771, Train Acc: 0.3454986429520125\n",
      "Test Loss: 0.4844067501652533, Test Acc: 0.34396671289875175\n",
      "precision  0.08581510780207849\n",
      "recall  0.19831593589499716\n",
      "f1  0.10335232383808095\n",
      "epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48392648509862607, Train Acc: 0.34572962984350636\n",
      "Test Loss: 0.4840597434557537, Test Acc: 0.3451225150254276\n",
      "precision  0.09784153549843926\n",
      "recall  0.1990717733498193\n",
      "f1  0.10399641656526878\n",
      "epoch:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48348087663359185, Train Acc: 0.3458451232892533\n",
      "Test Loss: 0.48362523799575263, Test Acc: 0.34489135460009246\n",
      "precision  0.09777895820191893\n",
      "recall  0.19893861755754233\n",
      "f1  0.10390982090609288\n",
      "epoch:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48318602793271914, Train Acc: 0.3458451232892533\n",
      "Test Loss: 0.48339619973551273, Test Acc: 0.345584835876098\n",
      "precision  0.09597957288765088\n",
      "recall  0.19924802644093592\n",
      "f1  0.10366645191397547\n",
      "epoch:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4827851682820496, Train Acc: 0.34590287001212683\n",
      "Test Loss: 0.4830550328344865, Test Acc: 0.34581599630143317\n",
      "precision  0.1068129062209842\n",
      "recall  0.19947124072665018\n",
      "f1  0.10410408551499228\n",
      "epoch:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48254023582085714, Train Acc: 0.3460183634578738\n",
      "Test Loss: 0.4828273056973146, Test Acc: 0.345584835876098\n",
      "precision  0.09785217103082532\n",
      "recall  0.19924802644093592\n",
      "f1  0.1036320458619151\n",
      "epoch:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48215871758657053, Train Acc: 0.3458451232892533\n",
      "Test Loss: 0.4823959840291967, Test Acc: 0.34581599630143317\n",
      "precision  0.10463921750771836\n",
      "recall  0.19947124072665018\n",
      "f1  0.10413803976235521\n",
      "epoch:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48179413189360415, Train Acc: 0.34607611018074724\n",
      "Test Loss: 0.48203637901137286, Test Acc: 0.345584835876098\n",
      "precision  0.08929499072356215\n",
      "recall  0.19915796794749857\n",
      "f1  0.1032278788127311\n",
      "epoch:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48159235461160094, Train Acc: 0.3460183634578738\n",
      "Test Loss: 0.4818081776549074, Test Acc: 0.34535367545076284\n",
      "precision  0.10000356951633053\n",
      "recall  0.19911487064865893\n",
      "f1  0.10356418986702524\n",
      "epoch:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48122326389584136, Train Acc: 0.3460183634578738\n",
      "Test Loss: 0.48151212763962675, Test Acc: 0.3451225150254276\n",
      "precision  0.08588494548828578\n",
      "recall  0.19889165636294465\n",
      "f1  0.10310696593007773\n",
      "epoch:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48082607725706483, Train Acc: 0.3460183634578738\n",
      "Test Loss: 0.48112571400676785, Test Acc: 0.34581599630143317\n",
      "precision  0.08932529561789937\n",
      "recall  0.19929112373977553\n",
      "f1  0.10327899035568741\n",
      "epoch:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4804049209358304, Train Acc: 0.3460183634578738\n",
      "Test Loss: 0.48076425091127967, Test Acc: 0.34581599630143317\n",
      "precision  0.10266047950502706\n",
      "recall  0.19938118223321286\n",
      "f1  0.10370280537608653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = train(model, train_loader, test_loader, optimizer, loss_func, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d76342e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4830681062025766, Test Acc: 0.34535367545076284\n",
      "precision  0.09428256326909681\n",
      "recall  0.19911487064865893\n",
      "f1  0.10361432501895125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = test(model, test_loader, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "312fd4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999537679149329"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb8782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
